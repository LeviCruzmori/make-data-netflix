# Tabalho realizado em uma mentoria da DIO- digital innovation one, no curso de 
# PYTHON DATA ANALITICS

# Repositorio de dados
https://githib.com/digitalinnovationone/netflix-dataset

# Ferramentas de documentação utilizadas.
# Python
https://www.python.org/downloads/release/python-3118/
# Pip
https://pypi.org/project/pip/
# Pandas
https://pandas.pydata.org/

# Ambiente virtual venv (virtual Enviroment)
### para criar o ambiente virtual
python -m venv venv
### para ativar o ambiente virtual
venv/scripts/activate

# pasta data -> raw ~sao dados  na sua forma mais crua.
# pasta data -> ready são os dados já polidos e tratados ou quando passou pelo processo de refinamento.


# pacotes utilizados e caminho para install
Pandas (pip install pandas)
Openpyxl(pip install openpyxl)
xlsxwrite(pip install xlsxwrite)

# Regras para tratamento de dados
-- prezar pela confiabilidade e rastreabilidade dos dados.

# sigla ETL processo de 3 etapas.
## extract
-- processo que você vai usar par extrair os dados de outro lugar.
## transform
-- camada de tratamento de transformação dos dados.
## load
-- local onde sera carregado os dados depois do tratamento tipo banco de dados/csv/fileserver 

># .gitignore
selecione os dados da pasta raw para não subir ao git.

# import pandas as pd
-- pandas -- para minupulação dos dados.
# import os
-- os -- ferramenta interna do python par manipular pasta dentro dosistema opracional entre outras utilidades.
# import glob
-- glob -- ferramneta para manipular diretórios e alquivos em massa.
 

